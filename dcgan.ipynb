{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Choose a condition to train the GAN on by typing its number')\n",
    "print(\"1. Barrett's Syndrome\")\n",
    "print('2. Esophagitis')\n",
    "print('3. Healthy')\n",
    "print('4. Hemorrhoids')\n",
    "print('5. Polyps')\n",
    "print('6. Ulcerative Colitis')\n",
    "\n",
    "to_train_on = input()\n",
    "while to_train_on not in ['1', '2', '3', '4', '5', '6']:\n",
    "  print('Invalid input')\n",
    "  to_train_on = input()\n",
    "\n",
    "labels = ['barretts', 'esophagitis', 'healthy', 'hemorrhoids', 'polyps', 'ulcerative-colitis']\n",
    "label = labels[int(to_train_on) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = paths.CONDITION_DATASET + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.keras.utils.image_dataset_from_directory(data_dir, label_mode=None, image_size=(100, 100), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = next(iter(train_images))\n",
    "random_index = np.random.choice(image_batch.shape[0])\n",
    "random_image = image_batch[random_index].numpy().astype(\"int32\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(random_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images to [-1, 1] which is the range of the tanh activation\n",
    "train_images = train_images.map(lambda x: (x - 127.5) / 127.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent dimension of the random noise\n",
    "LATENT_DIM = 100 \n",
    "# weight initializer for G per DCGAN paper\n",
    "WEIGHT_INIT = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02) \n",
    "# number of channels, 1 for gray scale and 3 for color images\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "  # create a Keras Sequential model \n",
    "  model = Sequential(name='generator')\n",
    "\n",
    "  # prepare for reshape: FC => BN => RN layers, note: input shape defined in the 1st Dense layer  \n",
    "  model.add(layers.Dense(5 * 5 * 512, input_dim=LATENT_DIM))\n",
    "  model.add(layers.ReLU())\n",
    "\n",
    "  # 1D => 3D: reshape the output of the previous layer \n",
    "  model.add(layers.Reshape((5, 5, 512)))\n",
    "\n",
    "  # upsample to 25x25\n",
    "  model.add(layers.Conv2DTranspose(256, (5, 5), strides=(5, 5),padding=\"same\", kernel_initializer=WEIGHT_INIT))\n",
    "  model.add((layers.ReLU()))\n",
    "\n",
    "  # upsample to 50x50\n",
    "  model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2),padding=\"same\", kernel_initializer=WEIGHT_INIT))\n",
    "  model.add((layers.ReLU()))\n",
    "\n",
    "  # upsample to 100x100\n",
    "  model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2),padding=\"same\", kernel_initializer=WEIGHT_INIT))\n",
    "  model.add((layers.ReLU()))\n",
    "\n",
    "  # final layer: Conv2D with tanh activation\n",
    "  model.add(layers.Conv2D(CHANNELS, (4, 4), padding=\"same\", activation=\"tanh\"))\n",
    "\n",
    "  # return the generator model\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(height, width, depth, alpha=0.2):\n",
    "  # create a Keras Sequential model\n",
    "  model = Sequential(name='discriminator')\n",
    "  input_shape = (height, width, depth)\n",
    "\n",
    "  # 1. first set of CONV => BN => leaky ReLU layers\n",
    "  model.add(layers.Conv2D(64, (4, 4), padding=\"same\", strides=(2, 2), input_shape=input_shape))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "  # 2. second set of CONV => BN => leacy ReLU layers\n",
    "  model.add(layers.Conv2D(128, (4, 4), padding=\"same\", strides=(2, 2)))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "  # 3. third set of CONV => BN => leacy ReLU layers\n",
    "  model.add(layers.Conv2D(128, (5, 5), padding=\"same\", strides=(5, 5)))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "  # flatten and apply dropout\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dropout(0.3))\n",
    "\n",
    "  # sigmoid in the last layer outputting a single value for binary classification\n",
    "  model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "  # return the discriminator model\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the discriminator model\n",
    "discriminator = build_discriminator(100, 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(keras.Model):\n",
    "  def __init__(self, discriminator, generator, latent_dim):\n",
    "    super().__init__()\n",
    "    self.discriminator = discriminator\n",
    "    self.generator = generator\n",
    "    self.latent_dim = latent_dim\n",
    "    self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "    self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "  def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "    super(DCGAN, self).compile()\n",
    "    self.d_optimizer = d_optimizer\n",
    "    self.g_optimizer = g_optimizer\n",
    "    self.loss_fn = loss_fn\n",
    "\n",
    "  @property\n",
    "  def metrics(self):\n",
    "    return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "  def train_step(self, real_images):\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "    noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "    # Step 1. Train the discriminator with both real images (label as 1) and fake images (classified as label as 0) \n",
    "    with tf.GradientTape() as tape:\n",
    "      # Compute discriminator loss on real images\n",
    "      pred_real = self.discriminator(real_images, training=True)\n",
    "      real_labels = tf.ones((batch_size, 1))\n",
    "      # UPDATED: apply one-sided label smoothing to real labels\n",
    "      real_labels += 0.05 * tf.random.uniform(tf.shape(real_labels)) \n",
    "      d_loss_real = self.loss_fn(real_labels, pred_real)\n",
    "\n",
    "      # Compute discriminator loss on fake images\n",
    "      fake_images = self.generator(noise)\n",
    "      pred_fake = self.discriminator(fake_images, training=True)\n",
    "      fake_labels = tf.zeros((batch_size, 1))\n",
    "      # UPDATED: add random noise to fake labels - not needed\n",
    "      # fake_labels += 0.05 * tf.random.uniform(tf.shape(fake_labels)) \n",
    "      d_loss_fake = self.loss_fn(fake_labels, pred_fake)\n",
    "\n",
    "      # total discriminator loss\n",
    "      d_loss = (d_loss_real + d_loss_fake)/2\n",
    "    \n",
    "    # Compute discriminator gradients\n",
    "    grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "    # Update discriminator weights\n",
    "    self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_variables))\n",
    "\n",
    "    # Step 2. Train the generator (do not update weights of the discriminator)\n",
    "    misleading_labels = tf.ones((batch_size, 1)) # G wants D to think the fake images are real (label as 1)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "      fake_images = self.generator(noise, training=True)\n",
    "      pred_fake = self.discriminator(fake_images, training=True)\n",
    "      g_loss = self.loss_fn(misleading_labels, pred_fake)\n",
    " \n",
    "    # Compute generator gradients\n",
    "    grads = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "    # Update generator wieghts\n",
    "    self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_variables))\n",
    "\n",
    "    self.d_loss_metric.update_state(d_loss)\n",
    "    self.g_loss_metric.update_state(g_loss)\n",
    "\n",
    "    return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "  def __init__(self, num_img=3, latent_dim=100):\n",
    "    self.num_img = num_img\n",
    "    self.latent_dim = latent_dim\n",
    "\n",
    "    # Create random noise seed for visualization during traing\n",
    "    self.seed = tf.random.normal([16, latent_dim])\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    generated_images = self.model.generator(self.seed)\n",
    "    generated_images = (generated_images * 127.5) + 127.5\n",
    "    generated_images.numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(self.num_img):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      img = keras.utils.array_to_img(generated_images[i]) \n",
    "      plt.imshow(img)\n",
    "      plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "  def on_train_end(self, logs=None):\n",
    "    self.model.generator.save('generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(discriminator=discriminator, generator=generator, latent_dim=LATENT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_LR = 0.0001 # UPDATED: discriminator learning rate\n",
    "G_LR = 0.0003 # UPDATED: generator learning rate\n",
    "\n",
    "dcgan.compile(\n",
    "  d_optimizer=keras.optimizers.Adam(learning_rate=D_LR, beta_1 = 0.5),\n",
    "  g_optimizer=keras.optimizers.Adam(learning_rate=G_LR, beta_1 = 0.5),  \n",
    "  loss_fn=keras.losses.BinaryCrossentropy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100 # number of epochs\n",
    "dcgan.fit(train_images, epochs=NUM_EPOCHS, callbacks=[GANMonitor(num_img=16, latent_dim=LATENT_DIM)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save(paths.GANS + label + '_generator')\n",
    "discriminator.save(paths.GANS + label + '_discriminator')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
